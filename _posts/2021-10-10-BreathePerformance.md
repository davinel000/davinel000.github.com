---
layout: project_for_catalogue
title: Breathe Performance
year: 2021
description: Sound-generative performance based on the appeal of sensory data to randomness
category: performance
id: 3
nav-menu: true
show_tile: false
---
## Idea

Opening the veil of others' sleep, watching them breathe in a minimalistic setup. When sound entities made of field recordings and synthetic oscillators subordinate to random generation principles. Where 3D soundscape subordinates to sensory data

## Long Description

15 virtual sound sources were flying around the audience with filtering parameters controlled separately and randomly by 4 performers in a quadro sound setup. 5 temporal phases meant different stages of sensible sleep, connected to different sets of sound (falling asleep, travelling, escaping from a chase, finding harmony and washing out with rain and sea). Breathing of the performers captured by sensors was their own adventure of finding within the soundscape entities connected to their own scenario and communicate with them. Course  "Electronic in Performative context" by prof. Mattia Bonafini (SoSe-21).

## Presentation

Kunstraum 34 Atelierhaus, Stuttgart, Germany, Xchanges X2, 10.10.21

## Links

- [performance recording](https://youtu.be/fQWevuhIIrw)
- [3D sound prototype video](https://www.youtube.com/watch?v=8B870D55sjY&t=12470s)
- [performance announcement](https://kunstraum34.de/xchanges/)

## Illustrations

- ![Image]('url') recording sound scenes
- ![Image]('url') building replication and a randomness network
- ![Image]('url') venue and team
- ![Image]('url') performance photo

## Format

electronic performance

## Instruments

Derivative TouchDesigner, ZigSim, Zoom H4n Pro, GyrOSC

## Authors

- Viacheslav Romanov: idea, virtual environment, perf.design
- *qianxunchen: performing with sensors
- Caroline Schlingemann: performing with sensors
- Melissa Wedekind: performing with sensors
- Chi Him Chik: saxophone
